import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

interface NewsSource {
  id: string;
  name: string;
  url: string;
  country: string;
  category: string;
  priority: number;
  scrape_config: Record<string, unknown>;
}

interface ScrapedItem {
  title: string;
  url: string;
  content: string;
  date?: string;
}

interface AIAnalysis {
  is_relevant: boolean;
  title: string;
  summary: string;
  effective_date: string | null;
  category: "digest" | "comments" | "urgent";
  keywords: string[];
}

// Extended keywords for filtering relevant business news (softened filter)
const RELEVANCE_KEYWORDS = [
  // Taxes
  "–Ω–∞–ª–æ–≥", "–Ω–¥—Å", "–ø–æ–¥–æ—Ö–æ–¥–Ω", "–ø—Ä–∏–±—ã–ª—å", "–Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω",
  // Accounting
  "–±—É—Ö—É—á–µ—Ç", "–±—É—Ö–≥–∞–ª—Ç–µ—Ä", "–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç", "–±–∞–ª–∞–Ω—Å", "—É—á–µ—Ç",
  // Inspections
  "–ø—Ä–æ–≤–µ—Ä–∫", "–∫–æ–Ω—Ç—Ä–æ–ª", "–∫–≥–∫", "–º–Ω—Å", "–∞—É–¥–∏—Ç",
  // Social security
  "—Ñ—Å–∑–Ω", "–ø–µ–Ω—Å–∏", "–ø–æ—Å–æ–±–∏", "—Å—Ç—Ä–∞—Ö–æ–≤", "—Å–æ—Ü—Å—Ç—Ä–∞—Ö",
  // Currency & Finance
  "–≤–∞–ª—é—Ç", "–∫—É—Ä—Å", "–Ω–∞—Ü–±–∞–Ω–∫", "—Å—Ç–∞–≤–∫", "–∫—Ä–µ–¥–∏—Ç",
  // Sanctions & Restrictions
  "—Å–∞–Ω–∫—Ü–∏", "–æ–≥—Ä–∞–Ω–∏—á–µ–Ω", "–∑–∞–ø—Ä–µ—Ç", "–±–ª–æ–∫–∏—Ä–æ–≤",
  // Licensing
  "–ª–∏—Ü–µ–Ω–∑–∏", "—Ä–∞–∑—Ä–µ—à–µ–Ω", "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç",
  // Business support
  "—Å—É–±—Å–∏–¥–∏", "–ª—å–≥–æ—Ç", "–ø–æ–¥–¥–µ—Ä–∂–∫", "–≥—Ä–∞–Ω—Ç",
  // Legal
  "–∫–æ–¥–µ–∫—Å", "–∑–∞–∫–æ–Ω", "–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω", "—É–∫–∞–∑", "–¥–µ–∫—Ä–µ—Ç", "–Ω–ø–∞",
  // Other
  "–∏–ø", "–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç", "—é—Ä–ª–∏—Ü", "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏",
  // Additional business terms (expanded)
  "–±–∏–∑–Ω–µ—Å", "–∫–æ–º–ø–∞–Ω–∏", "—Ñ–∏—Ä–º", "–ø—Ä–µ–¥–ø—Ä–∏—è—Ç", "–º–∞–ª—ã–π", "—Å—Ä–µ–¥–Ω–∏–π",
  "—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü", "–ª–∏–∫–≤–∏–¥–∞—Ü", "—Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü",
  "–¥–æ–≥–æ–≤–æ—Ä", "–∫–æ–Ω—Ç—Ä–∞–∫—Ç", "—Å–¥–µ–ª–∫",
  "—à—Ç—Ä–∞—Ñ", "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç", "–Ω–∞—Ä—É—à–µ–Ω",
  "—Ç–∞—Ä–∏—Ñ", "–ø–æ—à–ª–∏–Ω", "—Å–±–æ—Ä", "–ø–ª–∞—Ç",
  "—Ç—Ä—É–¥–æ–≤", "–∑–∞—Ä–ø–ª–∞—Ç", "–æ–∫–ª–∞–¥", "–≤—ã–ø–ª–∞—Ç",
  "–∏–º–ø–æ—Ä—Ç", "—ç–∫—Å–ø–æ—Ä—Ç", "–≤–Ω–µ—à–Ω–µ—ç–∫–æ–Ω–æ–º", "–≤—ç–¥",
  "–±–∞–Ω–∫—Ä–æ—Ç", "–Ω–µ–ø–ª–∞—Ç–µ–∂–µ—Å–ø–æ—Å–æ–±–Ω",
  "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω", "—ç—Ü–ø", "—Ü–∏—Ñ—Ä–æ–≤",
  "–º–∞—Ä–∫–∏—Ä–æ–≤–∫", "–ø—Ä–æ—Å–ª–µ–∂–∏–≤–∞–µ–º",
  "–∞—Ä–µ–Ω–¥", "–Ω–µ–¥–≤–∏–∂–∏–º", "–∏–º—É—â–µ—Å—Ç–≤",
  "–≥–æ—Å–∑–∞–∫—É–ø–∫", "—Ç–µ–Ω–¥–µ—Ä", "–∫–æ–Ω–∫—É—Ä—Å",
  "–º–∏–Ω—Ñ–∏–Ω", "–º–∏–Ω—ç–∫–æ–Ω–æ–º", "–º–∏–Ω—Ç—Ä—É–¥",
];

// Specific deep URLs for certain sources
const DEEP_URLS: Record<string, string[]> = {
  "pravo.by": [
    "/pravovaya-informatsiya/novosti-zakonodatelstva/",
    "/news/",
  ],
  "nalog.gov.by": [
    "/info/novosti/",
    "/news/",
  ],
};

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const supabaseUrl = Deno.env.get("SUPABASE_URL")!;
    const supabaseKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!;
    const firecrawlKey = Deno.env.get("FIRECRAWL_API_KEY");
    const lovableKey = Deno.env.get("LOVABLE_API_KEY");

    const supabase = createClient(supabaseUrl, supabaseKey);

    const { sourceId, limit = 5 } = await req.json().catch(() => ({}));

    // Fetch audience interests from last 48 hours for resonance matching
    const twoDaysAgo = new Date(Date.now() - 48 * 60 * 60 * 1000).toISOString().split('T')[0];
    const { data: recentTopics } = await supabase
      .from('audience_interests')
      .select('topic')
      .gte('last_discussed', twoDaysAgo);

    const audienceTopics = (recentTopics || []).map(t => t.topic.toLowerCase());
    console.log(`[monitor-news] Loaded ${audienceTopics.length} audience topics from last 48h`);

    // Fetch style profile for adaptive prompting
    const { data: channelData } = await supabase
      .from('telegram_publish_channels')
      .select('settings')
      .eq('is_active', true)
      .limit(1)
      .maybeSingle();

    const styleProfile = channelData?.settings?.style_profile || null;

    // Get active sources
    let query = supabase
      .from("news_sources")
      .select("*")
      .eq("is_active", true)
      .order("priority", { ascending: false });

    if (sourceId) {
      query = query.eq("id", sourceId);
    } else {
      query = query.limit(limit);
    }

    const { data: sources, error: sourcesError } = await query;

    if (sourcesError) {
      throw new Error(`Failed to fetch sources: ${sourcesError.message}`);
    }

    console.log(`[monitor-news] Processing ${sources?.length || 0} sources`);

    const results: { source: string; items: number; errors: string[] }[] = [];

    for (const source of sources || []) {
      const sourceResult = { source: source.name, items: 0, errors: [] as string[] };

      try {
        // Scrape source using Firecrawl with improved depth
        const scrapedItems = await scrapeSourceWithDepth(source, firecrawlKey);
        console.log(`[monitor-news] ${source.name}: scraped ${scrapedItems.length} items`);

        for (const item of scrapedItems) {
          try {
            // Check if already exists
            const { data: existing } = await supabase
              .from("news_content")
              .select("id")
              .eq("source_url", item.url)
              .maybeSingle();

            if (existing) {
              console.log(`[monitor-news] Skipping duplicate: ${item.url}`);
              continue;
            }

            // Quick relevance check (softened - any match passes)
            const contentLower = (item.title + " " + item.content).toLowerCase();
            const isQuickRelevant = RELEVANCE_KEYWORDS.some((kw) =>
              contentLower.includes(kw)
            );

            if (!isQuickRelevant) {
              console.log(`[monitor-news] Skipping irrelevant: ${item.title.slice(0, 50)}`);
              continue;
            }

            // AI analysis with style profile for adaptive prompting
            const analysis = await analyzeWithAI(item, lovableKey, styleProfile, audienceTopics);

            if (!analysis.is_relevant) {
              console.log(`[monitor-news] AI marked as irrelevant: ${item.title.slice(0, 50)}`);
              continue;
            }

            // Check resonance with audience interests
            const newsKeywords = (analysis.keywords || []).map(k => k.toLowerCase());
            const matchedTopics = audienceTopics.filter(topic =>
              newsKeywords.some(kw => 
                topic.includes(kw) || kw.includes(topic)
              ) ||
              item.title.toLowerCase().includes(topic) ||
              item.content.toLowerCase().includes(topic)
            );
            const isResonant = matchedTopics.length > 0;

            if (isResonant) {
              console.log(`[monitor-news] üî• Resonant news found! Topics: ${matchedTopics.join(', ')}`);
            }

            // Save to database
            const { error: insertError } = await supabase.from("news_content").insert({
              title: analysis.title || item.title,
              summary: analysis.summary,
              source: source.name,
              source_url: item.url,
              country: source.country,
              category: analysis.category || "digest",
              source_id: source.id,
              raw_content: item.content.slice(0, 10000),
              ai_summary: analysis.summary,
              effective_date: analysis.effective_date,
              keywords: analysis.keywords,
              news_priority: analysis.category === "urgent" ? "urgent" : "normal",
              telegram_status: "draft",
              scraped_at: new Date().toISOString(),
              is_published: false,
              created_by: null,
              is_resonant: isResonant,
              resonance_topics: matchedTopics,
            });

            if (insertError) {
              sourceResult.errors.push(`Insert error: ${insertError.message}`);
            } else {
              sourceResult.items++;
            }
          } catch (itemError) {
            sourceResult.errors.push(`Item error: ${itemError instanceof Error ? itemError.message : String(itemError)}`);
          }
        }

        // Update source last_scraped_at
        await supabase
          .from("news_sources")
          .update({
            last_scraped_at: new Date().toISOString(),
            last_error: sourceResult.errors.length > 0 ? sourceResult.errors.join("; ") : null,
          })
          .eq("id", source.id);
      } catch (sourceError) {
        const errMsg = sourceError instanceof Error ? sourceError.message : String(sourceError);
        sourceResult.errors.push(`Source error: ${errMsg}`);
        await supabase
          .from("news_sources")
          .update({ last_error: errMsg })
          .eq("id", source.id);
      }

      results.push(sourceResult);
    }

    const totalItems = results.reduce((sum, r) => sum + r.items, 0);
    console.log(`[monitor-news] Completed: ${totalItems} new items from ${results.length} sources`);

    return new Response(
      JSON.stringify({
        success: true,
        results,
        totalItems,
        sourcesProcessed: results.length,
      }),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  } catch (error) {
    console.error("[monitor-news] Error:", error);
    return new Response(
      JSON.stringify({ success: false, error: error instanceof Error ? error.message : String(error) }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  }
});

// Scrape with depth - use Map to discover URLs, then scrape individual pages
async function scrapeSourceWithDepth(
  source: NewsSource,
  firecrawlKey: string | undefined
): Promise<ScrapedItem[]> {
  if (!firecrawlKey) {
    console.log(`[monitor-news] No Firecrawl key, skipping ${source.name}`);
    return [];
  }

  try {
    const hostname = new URL(source.url).hostname;
    const allItems: ScrapedItem[] = [];

    // Step 1: Try to map the website to find article URLs
    let articleUrls: string[] = [];
    
    try {
      const mapResponse = await fetch("https://api.firecrawl.dev/v1/map", {
        method: "POST",
        headers: {
          Authorization: `Bearer ${firecrawlKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          url: source.url,
          limit: 30,
          includeSubdomains: false,
        }),
      });

      if (mapResponse.ok) {
        const mapData = await mapResponse.json();
        articleUrls = (mapData.links || []).filter((url: string) => {
          // Filter out image URLs and non-article links
          const lowerUrl = url.toLowerCase();
          return !lowerUrl.match(/\.(jpg|jpeg|png|gif|webp|svg|pdf|doc|docx|xls|xlsx)(\?|$)/i) &&
                 !lowerUrl.includes("/tag/") &&
                 !lowerUrl.includes("/category/") &&
                 !lowerUrl.includes("/author/") &&
                 url.length > 30; // Likely to be article URLs
        }).slice(0, 15);
        console.log(`[monitor-news] ${source.name}: mapped ${articleUrls.length} article URLs`);
      }
    } catch (mapError) {
      console.log(`[monitor-news] Map failed for ${source.name}, falling back to scrape`);
    }

    // Step 2: If no URLs from map, scrape the main page
    if (articleUrls.length === 0) {
      const scrapeResult = await scrapeUrl(source.url, firecrawlKey, source.country);
      if (scrapeResult) {
        const items = parseNewsFromMarkdown(scrapeResult, source.url);
        allItems.push(...items);
      }
    } else {
      // Step 3: Scrape individual article URLs (limit to 5 to save API calls)
      for (const articleUrl of articleUrls.slice(0, 5)) {
        try {
          const scrapeResult = await scrapeUrl(articleUrl, firecrawlKey, source.country);
          if (scrapeResult && scrapeResult.length > 100) {
            // Extract article from scraped content
            const title = extractTitle(scrapeResult);
            if (title && title.length > 10) {
              allItems.push({
                title: title.slice(0, 300),
                url: articleUrl,
                content: scrapeResult.slice(0, 5000),
              });
            }
          }
        } catch (articleError) {
          console.log(`[monitor-news] Failed to scrape article: ${articleUrl}`);
        }
      }
    }

    return allItems.slice(0, 10);
  } catch (error) {
    console.error(`[monitor-news] Scrape error for ${source.name}:`, error);
    return [];
  }
}

// Helper to scrape a single URL
async function scrapeUrl(url: string, firecrawlKey: string, country: string): Promise<string | null> {
  try {
    const response = await fetch("https://api.firecrawl.dev/v1/scrape", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${firecrawlKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        url: url,
        formats: ["markdown"],
        onlyMainContent: true,
        waitFor: 3000,
        location: {
          country: country === "by" ? "BY" : "RU",
          languages: ["ru"],
        },
      }),
    });

    if (!response.ok) {
      return null;
    }

    const data = await response.json();
    return data.data?.markdown || "";
  } catch {
    return null;
  }
}

// Extract title from markdown
function extractTitle(markdown: string): string {
  // Try to find H1 or first header
  const h1Match = markdown.match(/^#\s+(.+)$/m);
  if (h1Match) return h1Match[1].trim();

  // Try first bold text
  const boldMatch = markdown.match(/\*\*(.+?)\*\*/);
  if (boldMatch) return boldMatch[1].trim();

  // First line
  const firstLine = markdown.split("\n").find(line => line.trim().length > 20);
  return firstLine?.replace(/^[#*\d.]+\s*/, "").trim() || "";
}

function parseNewsFromMarkdown(markdown: string, baseUrl: string): ScrapedItem[] {
  const items: ScrapedItem[] = [];

  // Split by headers or list items
  const sections = markdown.split(/\n(?=#{1,3}\s|\*\s|\d+\.\s)/);

  for (const section of sections) {
    if (section.trim().length < 50) continue;

    // Extract title from first line
    const lines = section.trim().split("\n");
    const titleLine = lines[0].replace(/^[#*\d.]+\s*/, "").trim();

    if (titleLine.length < 10) continue;

    // Extract URL - prioritize non-image URLs
    let url = baseUrl;
    const urlMatches = section.matchAll(/\[([^\]]+)\]\(([^)]+)\)/g);
    for (const match of urlMatches) {
      const extractedUrl = match[2];
      // Skip image URLs
      if (!extractedUrl.match(/\.(jpg|jpeg|png|gif|webp|svg)(\?|$)/i)) {
        url = extractedUrl;
        break;
      }
    }

    // Clean content
    const content = lines.slice(1).join("\n").trim();

    if (titleLine && content.length > 20) {
      items.push({
        title: titleLine.slice(0, 300),
        url: url.startsWith("http") ? url : new URL(url, baseUrl).href,
        content: content.slice(0, 5000),
      });
    }
  }

  return items.slice(0, 10);
}

async function analyzeWithAI(
  item: ScrapedItem,
  lovableKey: string | undefined,
  styleProfile: Record<string, unknown> | null = null,
  audienceTopics: string[] = []
): Promise<AIAnalysis> {
  if (!lovableKey) {
    return {
      is_relevant: true,
      title: item.title,
      summary: item.content.slice(0, 500),
      effective_date: null,
      category: "digest",
      keywords: [],
    };
  }

  // Build adaptive style guidance
  let styleGuidance = '';
  if (styleProfile) {
    styleGuidance = `\n\n–°–¢–ò–õ–ï–í–û–ô –ü–†–û–§–ò–õ–¨ –ö–ê–ù–ê–õ–ê (–ø–∏—à–∏ –≤ —ç—Ç–æ–º —Å—Ç–∏–ª–µ):
- –¢–æ–Ω: ${styleProfile.tone || '–¥–µ–ª–æ–≤–æ–π'}
- –î–ª–∏–Ω–∞: ${styleProfile.avg_length || '—Å—Ä–µ–¥–Ω–∏–π'}
- –•–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã: ${(styleProfile.characteristic_phrases as string[] || []).slice(0, 5).join(', ')}
- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: ${(styleProfile.formatting as any)?.html_tags_used?.join(', ') || '<b>, <i>'}`;
  }

  // Build audience context
  let audienceContext = '';
  if (audienceTopics.length > 0) {
    audienceContext = `\n\n–ê–£–î–ò–¢–û–†–ò–Ø –°–ï–ô–ß–ê–° –û–ë–°–£–ñ–î–ê–ï–¢ (–µ—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å —Å–≤—è–∑–∞–Ω–∞ - –∞–∫—Ü–µ–Ω—Ç–∏—Ä—É–π):
${audienceTopics.slice(0, 10).join(', ')}`;
  }

  try {
    // Softened AI prompt - more inclusive for business news with adaptive style
    const systemPrompt = `–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä –±–∏–∑–Ω–µ—Å-–∏–∑–¥–∞–Ω–∏—è –¥–ª—è –±—É—Ö–≥–∞–ª—Ç–µ—Ä–æ–≤ –∏ –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª–µ–π –ë–µ–ª–∞—Ä—É—Å–∏ –∏ –†–æ—Å—Å–∏–∏.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç—å –∏ –≤–µ—Ä–Ω–∏ JSON:
{
  "is_relevant": true/false,
  "title": "–ö—Ä–∞—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ 100 —Å–∏–º–≤–æ–ª–æ–≤",
  "summary": "–û–ø–∏—Å–∞–Ω–∏–µ –¥–æ 200 —Å–ª–æ–≤: —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, –∫–æ–≥–æ –∫–∞—Å–∞–µ—Ç—Å—è, —á—Ç–æ –¥–µ–ª–∞—Ç—å",
  "effective_date": "YYYY-MM-DD –∏–ª–∏ null",
  "category": "urgent|digest|comments",
  "keywords": ["–Ω–∞–ª–æ–≥–∏", "–§–°–ó–ù", ...]
}

–ö—Ä–∏—Ç–µ—Ä–∏–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (is_relevant = true) - –®–ò–†–û–ö–ò–ô –§–ò–õ–¨–¢–†:
- –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –Ω–∞–ª–æ–≥–æ–≤–æ–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ
- –ù–æ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –±–∏–∑–Ω–µ—Å–∞
- –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã
- –ü—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å
- –ò–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∞–≤–æ–∫, —Å—Ä–æ–∫–æ–≤, —Ñ–æ—Ä–º –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç–∏
- –§–°–ó–ù, –ø–µ–Ω—Å–∏–∏, –ø–æ—Å–æ–±–∏—è
- –í–∞–ª—é—Ç–Ω–æ–µ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
- –¢—Ä—É–¥–æ–≤–æ–µ –ø—Ä–∞–≤–æ, –∑–∞—Ä–ø–ª–∞—Ç—ã
- –ì–æ—Å–∑–∞–∫—É–ø–∫–∏ –∏ —Ç–µ–Ω–¥–µ—Ä—ã
- –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è/–ª–∏–∫–≤–∏–¥–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å–∞
- –ú–∞—Ä–∫–∏—Ä–æ–≤–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤
- –≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–æ–±–æ—Ä–æ—Ç
- –í–≠–î, –∏–º–ø–æ—Ä—Ç/—ç–∫—Å–ø–æ—Ä—Ç
- –õ—é–±—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ú–û–ì–£–¢ –∑–∞—Ç—Ä–æ–Ω—É—Ç—å –±–∏–∑–Ω–µ—Å${styleGuidance}${audienceContext}

–ù–ï —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ (is_relevant = false) - —Ç–æ–ª—å–∫–æ —è–≤–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ:
- –°–ø–æ—Ä—Ç, —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è, –∫—É–ª—å—Ç—É—Ä–∞
- –ö—Ä–∏–º–∏–Ω–∞–ª—å–Ω–∞—è —Ö—Ä–æ–Ω–∏–∫–∞ (–Ω–µ —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å –±–∏–∑–Ω–µ—Å–æ–º)
- –ü–æ–≥–æ–¥–∞, –ø—Ä–∏—Ä–æ–¥–Ω—ã–µ —è–≤–ª–µ–Ω–∏—è
- –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ–ª–∏—Ç–∏–∫–æ–≤

–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:
- urgent: —Å—Ä–æ—á–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –≤—Å—Ç—É–ø–∞—é—â–∏–µ –≤ —Å–∏–ª—É –≤ –±–ª–∏–∂–∞–π—à–∏–µ 30 –¥–Ω–µ–π
- digest: –æ–±—ã—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞
- comments: —Ç—Ä–µ–±—É–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è —ç–∫—Å–ø–µ—Ä—Ç–∞

–í–ê–ñ–ù–û: –ï—Å–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—à—å—Å—è –≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ - —Å—Ç–∞–≤—å is_relevant = true

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown.`;

    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${lovableKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash",
        messages: [
          { role: "system", content: systemPrompt },
          {
            role: "user",
            content: `–ó–∞–≥–æ–ª–æ–≤–æ–∫: ${item.title}\n\n–¢–µ–∫—Å—Ç:\n${item.content.slice(0, 3000)}`,
          },
        ],
        max_tokens: 500,
        temperature: 0.3,
      }),
    });

    if (!response.ok) {
      console.error("[monitor-news] AI error:", response.status);
      return {
        is_relevant: true,
        title: item.title,
        summary: item.content.slice(0, 500),
        effective_date: null,
        category: "digest",
        keywords: [],
      };
    }

    const data = await response.json();
    const content = data.choices?.[0]?.message?.content?.trim() || "";

    const jsonMatch = content.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0]);
      return {
        is_relevant: parsed.is_relevant ?? true,
        title: parsed.title || item.title,
        summary: parsed.summary || item.content.slice(0, 500),
        effective_date: parsed.effective_date || null,
        category: parsed.category || "digest",
        keywords: parsed.keywords || [],
      };
    }

    throw new Error("No valid JSON in response");
  } catch (error) {
    console.error("[monitor-news] AI parse error:", error);
    return {
      is_relevant: true,
      title: item.title,
      summary: item.content.slice(0, 500),
      effective_date: null,
      category: "digest",
      keywords: [],
    };
  }
}
